# -*- coding: utf-8 -*-
"""AI_Analysit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1102Z3hn3FF2aJG4c06hDI-HLfp5Pnlqv
"""

import os
os.environ["OPENAI_API_KEY"] = "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"

"""# Tools for Langchain"""

# Core LangChain and related tools
!pip install -U langchain langchain-community openai chromadb wikipedia tiktoken langchain_openai

"""# Document Loader for CSV File"""

from langchain_community.document_loaders.csv_loader import CSVLoader
loader = CSVLoader("/content/TSLA.csv")
csv_doc = loader.load()

"""# Document Loader for Wikipedialoader"""

from langchain_community.document_loaders import WikipediaLoader

wiki_loader = WikipediaLoader(query="Tesla, Inc.", lang="en", load_max_docs=2)
wiki_docs = wiki_loader.load()

"""# Combining both documents loader"""

docs = csv_doc + wiki_docs
print(docs)

"""# Text splitter"""

from langchain.text_splitter import RecursiveCharacterTextSplitter
splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)
chunk = splitter.split_documents(docs)

len(chunk)

"""# Vector store and openai embedding"""

from langchain.vectorstores import Chroma  # or FAISS, Weaviate, etc.
from langchain.embeddings import OpenAIEmbeddings

embedding = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(docs, embedding=embedding, persist_directory="./chroma_db")

"""# Retriver"""

retriver = vectorstore.as_retriever()

"""# Test the retriver"""

retriver.invoke('give some highligs of the data')

"""# LLM model"""

llm = ChatOpenAI()

"""# import library for parser and chain"""

from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser

"""# REtriver page content function"""

def format_doc(retriver):
  context_text = "\n\n".join(doc.page_content for doc in retriver)
  return context_text

"""# Parallel chain"""

parallel_chain = RunnableParallel(
    {
        'context' : retriver | RunnableLambda(format_doc),
        'question' : RunnablePassthrough()
    }
)

"""# Test parallel chain"""

parallel_chain.invoke("What is the average daily trading volume")

"""# Parser"""

parser = StrOutputParser()

"""# Prompt for AI Business Analyst"""

from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

template = """You are an AI Business Analyst. You are a financial data analyst AI. Use the provided Tesla stock data to answer user queries.
If the data isn't sufficient, say "I don't know based on the data provided.
Context:
{context}

Question:
{question}
"""

prompt = PromptTemplate.from_template(template)

"""# Final chain"""

main_chain = parallel_chain | prompt | llm | parser

"""# Final result"""

main_chain.invoke("Based on the data, how did Tesla perform around the time of their stock split in August 2020")

main_chain.invoke("When did Tesla experience the highest one-day gain?")

!pip install gradio

"""# Code for UI"""

import pandas as pd
import gradio as gr

def analyze_csv(file, question):
    df = pd.read_csv(file.name)

    if "highest one-day gain" in question.lower():
        df["Gain"] = df["Close"] - df["Open"]
        max_gain_row = df.loc[df["Gain"].idxmax()]
        return f"Tesla experienced the highest one-day gain of ${max_gain_row['Gain']:.2f} on {max_gain_row['Date']}."

    elif "lowest one-day loss" in question.lower():
        df["Loss"] = df["Close"] - df["Open"]
        min_loss_row = df.loc[df["Loss"].idxmin()]
        return f"Tesla experienced the highest one-day loss of ${min_loss_row['Loss']:.2f} on {min_loss_row['Date']}."

    else:
        return "❌ Sorry, I can only answer questions about one-day gains/losses for now."

gr.Interface(
    fn=analyze_csv,
    inputs=[gr.File(label="Upload Tesla CSV"), gr.Textbox(label="Ask a Question")],
    outputs="text",
    title="AI Analyst – Tesla Data",
    description="Ask things like: 'When did Tesla experience the highest one-day gain?'"
).launch()

